{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidrampotdar/APP/blob/master/Copy_of_Mindora_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_wrq1npNzdDS",
        "outputId": "17a16408-b054-4bd0-d90d-90464fad8ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.10/dist-packages (0.3.25)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langchain_core\n",
            "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.14 (from langchain_community)\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.24.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.3)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_core) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_groq-0.2.3-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.13.1-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading marshmallow-3.24.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, groq, dataclasses-json, langchain_core, langchain_groq, langchain, langchain_community\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.12\n",
            "    Uninstalling langchain-0.3.12:\n",
            "      Successfully uninstalled langchain-0.3.12\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.13.1 httpx-sse-0.4.0 langchain-0.3.14 langchain_community-0.3.14 langchain_core-0.3.29 langchain_groq-0.2.3 marshmallow-3.24.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_groq langchain_core langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "LcWdWpjY1wZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(\n",
        "    temperature = 0,\n",
        "    groq_api_key = \"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\",\n",
        "    model_name = \"llama-3.3-70b-versatile\"\n",
        ")\n",
        "result = llm.invoke(\"Hello?\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH6h3f-szkNg",
        "outputId": "2ebf0b6d-b92d-412f-f186-81e8ea191f7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello. It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UosChuoLzyWb",
        "outputId": "eb4ef4c2-ff7e-40a6-e096-e8a6dcad3009"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/298.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IkazLzi00gJ",
        "outputId": "b7099544-19b4-488b-e986-1b39993093c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.5-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.2-py3-none-any.whl (606 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.2/606.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.5-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=2e16031e677b23bb91f34692375010c511813e0cc46b999f492a1991ad7f0655\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.2 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.7.5 protobuf-5.29.2 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vJRObEU02pA",
        "outputId": "c462c6f6-0981-4f90-f245-12c57e87017f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-groq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_gtsKA9zzsZ",
        "outputId": "0f035ab3-39c6-4dd0-98cd-cf280f31b60f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6PeLdUhxgOku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of Bot with Conversation History Feature"
      ],
      "metadata": {
        "id": "o8NgeHXKfH1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "\n",
        "def initialize_llm():\n",
        "    llm = ChatGroq(\n",
        "        temperature=0,\n",
        "        groq_api_key=\"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\",\n",
        "        model_name=\"llama-3.3-70b-versatile\"\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "def create_vector_db():\n",
        "    # Ensure the 'data' directory exists and contains PDF files\n",
        "    loader = DirectoryLoader(\"/content/sample_data/\", glob='*.pdf', loader_cls=PyPDFLoader)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
        "    vector_db.persist()\n",
        "\n",
        "    print(\"ChromaDB created and data saved\")\n",
        "    return vector_db\n",
        "\n",
        "class ConversationHistory:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def add_message(self, message_type, message):\n",
        "        self.history.append((message_type, message))\n",
        "\n",
        "    def get_context(self):\n",
        "        context = \"\\n\".join([f\"{t}: {m}\" for t, m in self.history])\n",
        "        return context if context else \"No prior conversation history.\"\n",
        "\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt_template = \"\"\"You are a compassionate mental health chatbot. Respond thoughtfully to the following question, considering the conversation history:\n",
        "    {context}\n",
        "    User: {question}\n",
        "    Chatbot:\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    return qa_chain\n",
        "\n",
        "def main():\n",
        "    print(\"Initializing Chatbot.........\")\n",
        "    llm = initialize_llm()\n",
        "\n",
        "    db_path = \"./chroma_db\"\n",
        "    if not os.path.exists(db_path):\n",
        "        vector_db = create_vector_db()\n",
        "    else:\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "\n",
        "    conversation_history = ConversationHistory()  # Initialize history *outside* the loop\n",
        "    qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nHuman: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Chatbot: Take Care of yourself, Goodbye!\")\n",
        "            break\n",
        "\n",
        "        conversation_history.add_message(\"Human\", query)\n",
        "        context = conversation_history.get_context()  # Get updated conversation history\n",
        "        # Pass context and query correctly to the chain\n",
        "        response = qa_chain({\"query\": f\"{context}\\nUser: {query}\"})\n",
        "        chatbot_reply = response['result']\n",
        "        conversation_history.add_message(\"Chatbot\", chatbot_reply)  # Save chatbot's response\n",
        "        print(f\"Chatbot: {chatbot_reply}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "dDlAQDA32MiU",
        "outputId": "0dbe136b-aef5-497e-9ec9-46744055c8c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Chatbot.........\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Directory not found: '/content/data/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4d8804657c24>\u001b[0m in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-4d8804657c24>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdb_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./chroma_db\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mvector_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vector_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceBgeEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sentence-transformers/all-MiniLM-L6-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-4d8804657c24>\u001b[0m in \u001b[0;36mcreate_vector_db\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Ensure the 'data' directory exists and contains PDF files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirectoryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*.pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtext_splitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_overlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_splitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/directory.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;34m\"\"\"Load documents.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlazy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/document_loaders/directory.py\u001b[0m in \u001b[0;36mlazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Directory not found: '{self.path}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected directory, got file: '{self.path}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Directory not found: '/content/data/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S_eaUPDl6LWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "def initialize_llm():\n",
        "  llm = ChatGroq(\n",
        "    temperature = 0,\n",
        "    groq_api_key = \"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\",\n",
        "    model_name = \"llama-3.3-70b-versatile\"\n",
        ")\n",
        "  return llm\n",
        "\n",
        "def create_vector_db():\n",
        "  loader = DirectoryLoader(\"/content/data/\", glob = '*.pdf', loader_cls = PyPDFLoader)\n",
        "  documents = loader.load()\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)\n",
        "  texts = text_splitter.split_documents(documents)\n",
        "  embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
        "  vector_db = Chroma.from_documents(texts, embeddings, persist_directory = './chroma_db')\n",
        "  vector_db.persist()\n",
        "\n",
        "  print(\"ChromaDB created and data saved\")\n",
        "\n",
        "  return vector_db\n",
        "\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "  retriever = vector_db.as_retriever()\n",
        "  prompt_templates = \"\"\" You are a compassionate mental health chatbot. Respond thoughtfully to the following question:\n",
        "    {context}\n",
        "    User: {question}\n",
        "    Chatbot: \"\"\"\n",
        "  PROMPT = PromptTemplate(template = prompt_templates, input_variables = ['context', 'question'])\n",
        "\n",
        "  qa_chain = RetrievalQA.from_chain_type(\n",
        "      llm = llm,\n",
        "      chain_type = \"stuff\",\n",
        "      retriever = retriever,\n",
        "      chain_type_kwargs = {\"prompt\": PROMPT}\n",
        "  )\n",
        "  return qa_chain\n",
        "\n",
        "\n",
        "print(\"Intializing Chatbot.........\")\n",
        "llm = initialize_llm()\n",
        "\n",
        "db_path = \"/content/chroma_db\"\n",
        "\n",
        "if not os.path.exists(db_path):\n",
        "  vector_db  = create_vector_db()\n",
        "else:\n",
        "  embeddings = HuggingFaceBgeEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
        "  vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "def chatbot_response(user_input, history = []):\n",
        "  if not user_input.strip():\n",
        "    return \"Please provide a valid input\", history\n",
        "  response = qa_chain.run(user_input)\n",
        "  history.append((user_input, response))\n",
        "  return \"\", history\n",
        "\n",
        "with gr.Blocks(theme = 'Respair/Shiki@1.2.1') as app:\n",
        "    gr.Markdown(\"# 🧠 Mental Health Chatbot 🤖\")\n",
        "    gr.Markdown(\"A compassionate chatbot designed to assist with mental well-being. Please note: For serious concerns, contact a professional.\")\n",
        "\n",
        "    chatbot = gr.ChatInterface(fn=chatbot_response, title=\"Mental Health Chatbot\")\n",
        "\n",
        "    gr.Markdown(\"This chatbot provides general support. For urgent issues, seek help from licensed professionals.\")\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "id": "AjjVLMmu2bqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firebase-admin\n"
      ],
      "metadata": {
        "id": "zdqo_C-2gPWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload the serviceAccountKey.json file\n"
      ],
      "metadata": {
        "id": "rxGmM6xnmcZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(\n",
        "    temperature = 0,\n",
        "    groq_api_key = \"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\",\n",
        "    model_name = \"llama-3.3-70b-versatile\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "mO4gUTgoKTuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integration of DB(FireBase) and Email Sending Feature without Conversation HIstory Feature"
      ],
      "metadata": {
        "id": "Xbe8LB_CetGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "# Firebase Connection Setup\n",
        "def setup_firebase():\n",
        "    if not firebase_admin._apps:\n",
        "        cred = credentials.Certificate(\"/content/project141-22a01-firebase-adminsdk-sgnh9-181e811b93.json\")\n",
        "        firebase_admin.initialize_app(cred)\n",
        "    db = firestore.client()\n",
        "    return db\n",
        "\n",
        "# Emotion Detection Function\n",
        "def detect_emotion(user_input):\n",
        "    model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
        "    emotion = emotion_labels[predicted_class]\n",
        "    confidence = torch.softmax(logits, dim=1)[0][predicted_class].item()\n",
        "    return emotion, confidence\n",
        "\n",
        "# Helper function to send email\n",
        "email_sent_users = set()\n",
        "\n",
        "def send_email(user_email, city):\n",
        "    global email_sent_users  # Reference the global set\n",
        "\n",
        "    if user_email in email_sent_users:\n",
        "        print(f\"Email already sent to {user_email}.\")\n",
        "        return  # Exit the function\n",
        "    helpline_numbers = {\n",
        "        'mumbai': 'Mpower 1on1: 1800-120-820050',\n",
        "        'pune': 'Connecting NGO: +91-9922001122',\n",
        "        'nagpur': 'Jeevan Jyoti Suicide Prevention Centre: +91-712-2775555',\n",
        "        'nashik': 'Connecting NGO: +91-9922001122',\n",
        "        'aurangabad': 'Connecting NGO: +91-9922001122',\n",
        "        'solapur': 'Connecting NGO: +91-9922001122',\n",
        "        'kolhapur': 'Tele-MANAS: 14416',\n",
        "        'thane': 'Tele-MANAS: 14416',\n",
        "        'amravati': 'Tele-MANAS: 14416',\n",
        "        'nanded': 'Tele-MANAS: 14416',\n",
        "        'sangli': 'Tele-MANAS: 14416',\n",
        "        'jalgaon': 'Tele-MANAS: 14416',\n",
        "        'akola': 'Tele-MANAS: 14416',\n",
        "        'latur': 'Tele-MANAS: 14416',\n",
        "        'dhule': 'Tele-MANAS: 14416',\n",
        "        'malegaon': 'Tele-MANAS: 14416',\n",
        "        'bhusawal': 'Tele-MANAS: 14416',\n",
        "        'beed': 'Tele-MANAS: 14416',\n",
        "        'chandrapur': 'Tele-MANAS: 14416',\n",
        "        'parbhani': 'Tele-MANAS: 14416',\n",
        "        'yavatmal': 'Tele-MANAS: 14416',\n",
        "        'osmanabad': 'Tele-MANAS: 14416',\n",
        "        'navi mumbai': 'Mpower 1on1: 1800-120-820050',\n",
        "        'kalyan': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ulhasnagar': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ambarnath': 'Mpower 1on1: 1800-120-820050',\n",
        "        'dombivli': 'Mpower 1on1: 1800-120-820050',\n",
        "        'bhiwandi': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ratnagiri': 'Mpower 1on1: 1800-120-820050',\n",
        "        'satara': 'Mpower 1on1: 1800-120-820050',\n",
        "        'sindhudurg': 'Mpower 1on1: 1800-120-820050',\n",
        "        'wardha': 'Mpower 1on1: 1800-120-820050',\n",
        "        'gondia': 'Mpower 1on1: 1800-120-820050',\n",
        "        'bhandara': 'Mpower 1on1: 1800-120-820050',\n",
        "        'washim': 'Mpower 1on1: 1800-120-820050',\n",
        "        'hingoli': 'Mpower 1on1: 1800-120-820050',\n",
        "        'gadchiroli': 'Mpower 1on1: 1800-120-820050',\n",
        "    }\n",
        "\n",
        "    if city not in helpline_numbers:\n",
        "        helpline_numbers[city] = 'No helpline data available for your city.'\n",
        "\n",
        "    sender_email = \"pruthviraj.22420262@viit.ac.in\"\n",
        "    sender_password = \"22420262\"\n",
        "    receiver_email = user_email\n",
        "\n",
        "    subject = \"Mental Health Support: Helpline Number\"\n",
        "    body = f\"\"\"\n",
        "    Dear {user_email},\n",
        "\n",
        "    We noticed that you're going through a tough time. Your emotional well-being is important to us.\n",
        "\n",
        "    Here is the helpline number for your city ({city}):\n",
        "    {helpline_numbers[city]}\n",
        "\n",
        "    Please reach out to the helpline for any support you may need.\n",
        "\n",
        "    Take care,\n",
        "    Your Mental Health Chatbot\n",
        "    \"\"\"\n",
        "\n",
        "    message = MIMEMultipart()\n",
        "    message['From'] = sender_email\n",
        "    message['To'] = receiver_email\n",
        "    message['Subject'] = subject\n",
        "    message.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, sender_password)\n",
        "        text = message.as_string()\n",
        "        server.sendmail(sender_email, receiver_email, text)\n",
        "        email_sent_users.add(receiver_email)\n",
        "        print(f\"Email sent successfully to {receiver_email}\")\n",
        "        server.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending email: {e}\")\n",
        "\n",
        "# Vector Database Creation\n",
        "def create_vector_db():\n",
        "    loader = DirectoryLoader(\"/content/data/\", glob='*.pdf', loader_cls=PyPDFLoader)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
        "    vector_db.persist()\n",
        "    print(\"ChromaDB created and data saved\")\n",
        "    return vector_db\n",
        "\n",
        "# QA Chain Setup\n",
        "class ConversationHistory:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def add_message(self, message_type, message):\n",
        "        \"\"\"Adds a message to the conversation history.\"\"\"\n",
        "        self.history.append((message_type, message))\n",
        "\n",
        "    def get_context(self):\n",
        "        \"\"\"Retrieves the conversation history formatted as context.\"\"\"\n",
        "        return \"\\n\".join([f\"{t}: {m}\" for t, m in self.history]) if self.history else \"No prior conversation history.\"\n",
        "\n",
        "\n",
        "def setup_qa_chain(vector_db, llm, user_info, conversation_history):\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt_template = f\"\"\"\n",
        "    You are a compassionate mental health chatbot. Respond thoughtfully to the following question:\n",
        "    User Info:\n",
        "    Name: {user_info['name']}\n",
        "    Age: {user_info['age']}\n",
        "    City: {user_info['city']}\n",
        "    Gender: {user_info['gender']}\n",
        "\n",
        "    Previous Conversation question:\n",
        "    {query}\n",
        "\n",
        "\n",
        "    Context: {{context}}\n",
        "    User: {{question}}\n",
        "    Chatbot: \"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    return qa_chain\n",
        "\n",
        "# Store User Data in Firestore\n",
        "def store_user_data(db, user_info):\n",
        "    user_ref = db.collection(\"users\").document(user_info['name'])\n",
        "    user_ref.set(user_info)\n",
        "\n",
        "# Store Chat Data in Firestore\n",
        "def store_chat_data(db, user_info, query, response, emotion, confidence):\n",
        "    user_chat_ref = db.collection(\"users\").document(user_info['name']).collection(\"chat_history\")\n",
        "\n",
        "    chat_entry = {\n",
        "        \"user_name\": user_info['name'],\n",
        "        \"user_query\": query,\n",
        "        \"chatbot_response\": response,\n",
        "        \"emotion_detected\": emotion,\n",
        "        \"confidence\": confidence,\n",
        "        \"timestamp\": datetime.datetime.now()\n",
        "    }\n",
        "\n",
        "    user_chat_ref.add(chat_entry)\n",
        "\n",
        "# Main Chatbot Function\n",
        "def main():\n",
        "    print(\"Initializing Chatbot.........\")\n",
        "    db = setup_firebase()\n",
        "\n",
        "    # Initialize the LLM\n",
        "    llm = ChatGroq(\n",
        "        temperature=0,\n",
        "        groq_api_key=\"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\",\n",
        "        model_name=\"llama-3.3-70b-versatile\"\n",
        "    )\n",
        "\n",
        "    db_path = \"/content/chroma_db\"\n",
        "\n",
        "    if not os.path.exists(db_path):\n",
        "        vector_db = create_vector_db()\n",
        "    else:\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "\n",
        "    user_info = {}\n",
        "    print(\"Welcome! Before we start, please provide some information about yourself.\")\n",
        "    # user_info['name'] = input(\"What is your name? \")\n",
        "    # user_info['age'] = input(\"What is your age? \")\n",
        "    # user_info['city'] = input(\"What is your city? \")\n",
        "    # user_info['gender'] = input(\"What is your gender? \")\n",
        "    # user_info['email'] = input(\"Please provide your email address for support: \")\n",
        "\n",
        "    ########\n",
        "\n",
        "    user_info['name'] = \"ex\"\n",
        "    user_info['age'] = \"ex\"\n",
        "    user_info['city'] = \"ex\"\n",
        "    user_info['gender'] = \"ex\"\n",
        "    user_info['email'] = \"example@gmail.com\"\n",
        "\n",
        "    store_user_data(db, user_info)\n",
        "\n",
        "    # Initialize conversation history\n",
        "    conversation_history = \"\"\n",
        "\n",
        "    qa_chain = setup_qa_chain(vector_db, llm, user_info, conversation_history)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nHuman: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Chatbot: Take care of yourself, Goodbye!\")\n",
        "            break\n",
        "\n",
        "        emotion, confidence = detect_emotion(query)\n",
        "        print(f\"Emotion Detected: {emotion} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "        if emotion == \"sadness\" and confidence > 0.75:\n",
        "            send_email(user_info['email'], user_info['city'])\n",
        "\n",
        "        # Update conversation history and get response\n",
        "        response = qa_chain.run(query)\n",
        "        conversation_history += f\"\\nHuman: {query}\\nChatbot: {response}\"\n",
        "\n",
        "        print(f\"Chatbot: {response}\")\n",
        "        store_chat_data(db, user_info, query, response, emotion, confidence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "Pt6qrqW3X2bN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integration of DB(FireBase) and Email Sending Feature with Conversation HIstory Feature"
      ],
      "metadata": {
        "id": "bcm1p5OQeiWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "# Firebase Connection Setup\n",
        "def setup_firebase():\n",
        "    if not firebase_admin._apps:\n",
        "        cred = credentials.Certificate(\"/content/project141-22a01-firebase-adminsdk-sgnh9-181e811b93.json\")\n",
        "        firebase_admin.initialize_app(cred)\n",
        "    db = firestore.client()\n",
        "    return db\n",
        "\n",
        "# Emotion Detection Function\n",
        "def detect_emotion(user_input):\n",
        "    model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
        "    emotion = emotion_labels[predicted_class]\n",
        "    confidence = torch.softmax(logits, dim=1)[0][predicted_class].item()\n",
        "    return emotion, confidence\n",
        "\n",
        "# Helper function to send email\n",
        "email_sent_users = set()\n",
        "\n",
        "def send_email(user_email, city):\n",
        "    global email_sent_users  # Reference the global set\n",
        "\n",
        "    if user_email in email_sent_users:\n",
        "        print(f\"Email already sent to {user_email}.\")\n",
        "        return  # Exit the function\n",
        "    helpline_numbers = {\n",
        "        'mumbai': 'Mpower 1on1: 1800-120-820050',\n",
        "        'pune': 'Connecting NGO: +91-9922001122',\n",
        "        'nagpur': 'Jeevan Jyoti Suicide Prevention Centre: +91-712-2775555',\n",
        "        'nashik': 'Connecting NGO: +91-9922001122',\n",
        "        'aurangabad': 'Connecting NGO: +91-9922001122',\n",
        "        'solapur': 'Connecting NGO: +91-9922001122',\n",
        "        'kolhapur': 'Tele-MANAS: 14416',\n",
        "        'thane': 'Tele-MANAS: 14416',\n",
        "        'amravati': 'Tele-MANAS: 14416',\n",
        "        'nanded': 'Tele-MANAS: 14416',\n",
        "        'sangli': 'Tele-MANAS: 14416',\n",
        "        'jalgaon': 'Tele-MANAS: 14416',\n",
        "        'akola': 'Tele-MANAS: 14416',\n",
        "        'latur': 'Tele-MANAS: 14416',\n",
        "        'dhule': 'Tele-MANAS: 14416',\n",
        "        'malegaon': 'Tele-MANAS: 14416',\n",
        "        'bhusawal': 'Tele-MANAS: 14416',\n",
        "        'beed': 'Tele-MANAS: 14416',\n",
        "        'chandrapur': 'Tele-MANAS: 14416',\n",
        "        'parbhani': 'Tele-MANAS: 14416',\n",
        "        'yavatmal': 'Tele-MANAS: 14416',\n",
        "        'osmanabad': 'Tele-MANAS: 14416',\n",
        "        'navi mumbai': 'Mpower 1on1: 1800-120-820050',\n",
        "        'kalyan': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ulhasnagar': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ambarnath': 'Mpower 1on1: 1800-120-820050',\n",
        "        'dombivli': 'Mpower 1on1: 1800-120-820050',\n",
        "        'bhiwandi': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ratnagiri': 'Mpower 1on1: 1800-120-820050',\n",
        "        'satara': 'Mpower 1on1: 1800-120-820050',\n",
        "        'sindhudurg': 'Mpower 1on1: 1800-120-820050',\n",
        "        'wardha': 'Mpower 1on1: 1800-120-820050',\n",
        "        'gondia': 'Mpower 1on1: 1800-120-820050',\n",
        "        'bhandara': 'Mpower 1on1: 1800-120-820050',\n",
        "        'washim': 'Mpower 1on1: 1800-120-820050',\n",
        "        'hingoli': 'Mpower 1on1: 1800-120-820050',\n",
        "        'gadchiroli': 'Mpower 1on1: 1800-120-820050',\n",
        "    }\n",
        "\n",
        "    if city not in helpline_numbers:\n",
        "        helpline_numbers[city] = 'No helpline data available for your city.'\n",
        "\n",
        "    sender_email = \"pruthviraj.22420262@viit.ac.in\"\n",
        "    sender_password = \"22420262\"\n",
        "    receiver_email = user_email\n",
        "\n",
        "    subject = \"Mental Health Support: Helpline Number\"\n",
        "    body = f\"\"\"\n",
        "    Dear {user_email},\n",
        "\n",
        "    We noticed that you're going through a tough time. Your emotional well-being is important to us.\n",
        "\n",
        "    Here is the helpline number for your city ({city}):\n",
        "    {helpline_numbers[city]}\n",
        "\n",
        "    Please reach out to the helpline for any support you may need.\n",
        "\n",
        "    Take care,\n",
        "    Your Mental Health Chatbot\n",
        "    \"\"\"\n",
        "\n",
        "    message = MIMEMultipart()\n",
        "    message['From'] = sender_email\n",
        "    message['To'] = receiver_email\n",
        "    message['Subject'] = subject\n",
        "    message.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, sender_password)\n",
        "        text = message.as_string()\n",
        "        server.sendmail(sender_email, receiver_email, text)\n",
        "        email_sent_users.add(receiver_email)\n",
        "        print(f\"Email sent successfully to {receiver_email}\")\n",
        "        server.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending email: {e}\")\n",
        "\n",
        "# Vector Database Creation\n",
        "def create_vector_db():\n",
        "    loader = DirectoryLoader(\"/content/data/\", glob='*.pdf', loader_cls=PyPDFLoader)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
        "    vector_db.persist()\n",
        "    print(\"ChromaDB created and data saved\")\n",
        "    return vector_db\n",
        "\n",
        "# QA Chain Setup\n",
        "class ConversationHistory:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def add_message(self, message_type, message):\n",
        "        self.history.append((message_type, message))\n",
        "\n",
        "    def get_context(self):\n",
        "        context = \"\\n\".join([f\"{t}: {m}\" for t, m in self.history])\n",
        "        return context if context else \"No prior conversation history.\"\n",
        "\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt_template = \"\"\"You are a compassionate mental health chatbot. Respond thoughtfully to the following question, considering the conversation history:\n",
        "    {context}\n",
        "    User: {question}\n",
        "    Chatbot:\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    return qa_chain\n",
        "\n",
        "def store_user_data(db, user_info):\n",
        "    user_ref = db.collection(\"users\").document(user_info['name'])\n",
        "    user_ref.set(user_info)\n",
        "\n",
        "def store_chat_data(db, user_info, query, response, emotion, confidence):\n",
        "    user_chat_ref = db.collection(\"users\").document(user_info['name']).collection(\"chat_history\")\n",
        "\n",
        "    chat_entry = {\n",
        "        \"user_name\": user_info['name'],\n",
        "        \"user_query\": query,\n",
        "        \"chatbot_response\": response,\n",
        "        \"emotion_detected\": emotion,\n",
        "        \"confidence\": confidence,\n",
        "        \"timestamp\": datetime.datetime.now()\n",
        "    }\n",
        "\n",
        "    user_chat_ref.add(chat_entry)\n",
        "\n",
        "def main():\n",
        "    print(\"Initializing Chatbot.........\")\n",
        "    db = setup_firebase()\n",
        "\n",
        "    llm = ChatGroq(\n",
        "        temperature=0,\n",
        "        groq_api_key=\"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\",\n",
        "        model_name=\"llama-3.3-70b-versatile\"\n",
        "    )\n",
        "\n",
        "    db_path = \"/content/chroma_db\"\n",
        "\n",
        "    if not os.path.exists(db_path):\n",
        "        vector_db = create_vector_db()\n",
        "    else:\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "\n",
        "    user_info = {}\n",
        "    print(\"Welcome! Before we start, please provide some information about yourself.\")\n",
        "    user_info['name'] = input(\"What is your name? \")\n",
        "    user_info['age'] = input(\"What is your age? \")\n",
        "    user_info['city'] = input(\"What is your city? \")\n",
        "    user_info['gender'] = input(\"What is your gender? \")\n",
        "    user_info['email'] = input(\"Please provide your email address for support: \")\n",
        "\n",
        "# ... (rest of your code)\n",
        "    store_user_data(db, user_info)\n",
        "\n",
        "    conversation_history = ConversationHistory()  # Initialize history\n",
        "    qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nHuman: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Chatbot: Take care of yourself, Goodbye!\")\n",
        "            break\n",
        "\n",
        "        emotion, confidence = detect_emotion(query)\n",
        "        print(f\"Emotion Detected: {emotion} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "        if emotion == \"sadness\" and confidence > 0.75:\n",
        "            send_email(user_info['email'], user_info['city'])\n",
        "\n",
        "        conversation_history.add_message(\"Human\", query)\n",
        "        context = conversation_history.get_context()\n",
        "        response = qa_chain({\"query\": f\"{context}\\nUser: {query}\"})\n",
        "        chatbot_reply = response['result']\n",
        "        conversation_history.add_message(\"Chatbot\", chatbot_reply)\n",
        "\n",
        "        print(f\"Chatbot: {chatbot_reply}\")\n",
        "        store_chat_data(db, user_info, query, chatbot_reply, emotion, confidence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "V7HMypUrUw57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "# Firebase Connection Setup\n",
        "def setup_firebase():\n",
        "    if not firebase_admin._apps:\n",
        "        cred = credentials.Certificate(\"/content/project141-22a01-firebase-adminsdk-sgnh9-181e811b93.json\")\n",
        "        firebase_admin.initialize_app(cred)\n",
        "    db = firestore.client()\n",
        "    return db\n",
        "\n",
        "# Emotion Detection Function\n",
        "def detect_emotion(user_input):\n",
        "    model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()\n",
        "    emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\", \"sadness\", \"surprise\"]\n",
        "    emotion = emotion_labels[predicted_class]\n",
        "    confidence = torch.softmax(logits, dim=1)[0][predicted_class].item()\n",
        "    return emotion, confidence\n",
        "\n",
        "# Helper function to send email\n",
        "email_sent_users = set()\n",
        "\n",
        "def send_email(user_email, city):\n",
        "    global email_sent_users  # Reference the global set\n",
        "\n",
        "    if user_email in email_sent_users:\n",
        "        print(f\"Email already sent to {user_email}.\")\n",
        "        return  # Exit the function\n",
        "    helpline_numbers = {\n",
        "        'mumbai': 'Mpower 1on1: 1800-120-820050',\n",
        "        'pune': 'Connecting NGO: +91-9922001122',\n",
        "        'nagpur': 'Jeevan Jyoti Suicide Prevention Centre: +91-712-2775555',\n",
        "        'nashik': 'Connecting NGO: +91-9922001122',\n",
        "        'aurangabad': 'Connecting NGO: +91-9922001122',\n",
        "        'solapur': 'Connecting NGO: +91-9922001122',\n",
        "        'kolhapur': 'Tele-MANAS: 14416',\n",
        "        'thane': 'Tele-MANAS: 14416',\n",
        "        'amravati': 'Tele-MANAS: 14416',\n",
        "        'nanded': 'Tele-MANAS: 14416',\n",
        "        'sangli': 'Tele-MANAS: 14416',\n",
        "        'jalgaon': 'Tele-MANAS: 14416',\n",
        "        'akola': 'Tele-MANAS: 14416',\n",
        "        'latur': 'Tele-MANAS: 14416',\n",
        "        'dhule': 'Tele-MANAS: 14416',\n",
        "        'malegaon': 'Tele-MANAS: 14416',\n",
        "        'bhusawal': 'Tele-MANAS: 14416',\n",
        "        'beed': 'Tele-MANAS: 14416',\n",
        "        'chandrapur': 'Tele-MANAS: 14416',\n",
        "        'parbhani': 'Tele-MANAS: 14416',\n",
        "        'yavatmal': 'Tele-MANAS: 14416',\n",
        "        'osmanabad': 'Tele-MANAS: 14416',\n",
        "        'navi mumbai': 'Mpower 1on1: 1800-120-820050',\n",
        "        'kalyan': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ulhasnagar': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ambarnath': 'Mpower 1on1: 1800-120-820050',\n",
        "        'dombivli': 'Mpower 1on1: 1800-120-820050',\n",
        "        'bhiwandi': 'Mpower 1on1: 1800-120-820050',\n",
        "        'ratnagiri': 'Mpower 1on1: 1800-120-820050',\n",
        "        'satara': 'Mpower 1on1: 1800-120-820050',\n",
        "        'sindhudurg': 'Mpower 1on1: 1800-120-820050',\n",
        "        'wardha': 'Mpower 1on1: 1800-120-820050',\n",
        "        'gondia': 'Mpower 1on1: 1800-120-820050',\n",
        "        'bhandara': 'Mpower 1on1: 1800-120-820050',\n",
        "        'washim': 'Mpower 1on1: 1800-120-820050',\n",
        "        'hingoli': 'Mpower 1on1: 1800-120-820050',\n",
        "        'gadchiroli': 'Mpower 1on1: 1800-120-820050',\n",
        "    }\n",
        "\n",
        "    if city not in helpline_numbers:\n",
        "        helpline_numbers[city] = 'No helpline data available for your city.'\n",
        "\n",
        "    sender_email = \"pruthviraj.22420262@viit.ac.in\"\n",
        "    sender_password = \"22420262\"\n",
        "    receiver_email = user_email\n",
        "\n",
        "    subject = \"Mental Health Support: Helpline Number\"\n",
        "    body = f\"\"\"\n",
        "    Dear {user_email},\n",
        "\n",
        "    We noticed that you're going through a tough time. Your emotional well-being is important to us.\n",
        "\n",
        "    Here is the helpline number for your city ({city}):\n",
        "    {helpline_numbers[city]}\n",
        "\n",
        "    Please reach out to the helpline for any support you may need.\n",
        "\n",
        "    Take care,\n",
        "    Your Mental Health Chatbot\n",
        "    \"\"\"\n",
        "\n",
        "    message = MIMEMultipart()\n",
        "    message['From'] = sender_email\n",
        "    message['To'] = receiver_email\n",
        "    message['Subject'] = subject\n",
        "    message.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "    try:\n",
        "        server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        server.starttls()\n",
        "        server.login(sender_email, sender_password)\n",
        "        text = message.as_string()\n",
        "        server.sendmail(sender_email, receiver_email, text)\n",
        "        email_sent_users.add(receiver_email)\n",
        "        print(f\"Email sent successfully to {receiver_email}\")\n",
        "        server.quit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending email: {e}\")\n",
        "\n",
        "# Vector Database Creation\n",
        "def create_vector_db():\n",
        "    loader = DirectoryLoader(\"/content/data/\", glob='*.pdf', loader_cls=PyPDFLoader)\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "    vector_db = Chroma.from_documents(texts, embeddings, persist_directory='./chroma_db')\n",
        "    vector_db.persist()\n",
        "    print(\"ChromaDB created and data saved\")\n",
        "    return vector_db\n",
        "\n",
        "# QA Chain Setup\n",
        "class ConversationHistory:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def add_message(self, message_type, message):\n",
        "        self.history.append((message_type, message))\n",
        "\n",
        "    def get_context(self):\n",
        "        context = \"\\n\".join([f\"{t}: {m}\" for t, m in self.history[-5:]])  # Only keep last 5 messages for context\n",
        "        return context if context else \"No prior conversation history.\"\n",
        "\n",
        "def setup_qa_chain(vector_db, llm):\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    prompt_template = \"\"\"You are Dr. James, a highly experienced and empathetic mental health professional having a one-on-one therapy session.\n",
        "    Maintain a warm, professional tone while showing genuine concern for the patient's well-being.\n",
        "\n",
        "    Important guidelines:\n",
        "    - Address the patient's emotions with validation and understanding\n",
        "    - Use therapeutic techniques like reflective listening and open-ended questions\n",
        "    - Provide gentle guidance and coping strategies when appropriate\n",
        "    - Maintain professional boundaries while being supportive\n",
        "    - If you sense any risk of self-harm, emphasize the importance of seeking immediate help\n",
        "\n",
        "    Previous conversation context:\n",
        "    {context}\n",
        "\n",
        "    Patient: {question}\n",
        "\n",
        "    Dr. James:\"\"\"\n",
        "\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": PROMPT}\n",
        "    )\n",
        "    return qa_chain\n",
        "\n",
        "def store_user_data(db, user_info):\n",
        "    user_ref = db.collection(\"users\").document(user_info['name'])\n",
        "    user_ref.set(user_info)\n",
        "\n",
        "def store_chat_data(db, user_info, query, response, emotion, confidence):\n",
        "    user_chat_ref = db.collection(\"users\").document(user_info['name']).collection(\"chat_history\")\n",
        "    chat_entry = {\n",
        "        \"user_name\": user_info['name'],\n",
        "        \"user_query\": query,\n",
        "        \"chatbot_response\": response,\n",
        "        \"emotion_detected\": emotion,\n",
        "        \"confidence\": confidence,\n",
        "        \"timestamp\": datetime.datetime.now()\n",
        "    }\n",
        "    user_chat_ref.add(chat_entry)\n",
        "\n",
        "def main():\n",
        "    print(\"\\n🌟 Welcome to Your Personal Therapy Session with Dr. James 🌟\")\n",
        "    print(\"\\nInitializing your secure therapy environment...\")\n",
        "    db = setup_firebase()\n",
        "\n",
        "    llm = ChatGroq(\n",
        "        temperature=0.7,  # Increased for more natural, empathetic responses\n",
        "        groq_api_key=\"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\",\n",
        "        model_name=\"llama-3.3-70b-versatile\"\n",
        "    )\n",
        "\n",
        "    db_path = \"/content/chroma_db\"\n",
        "    if not os.path.exists(db_path):\n",
        "        vector_db = create_vector_db()\n",
        "    else:\n",
        "        embeddings = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "        vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "\n",
        "    print(\"\\n📋 Before we begin, I'll need some information to provide you with the best support.\")\n",
        "    user_info = {}\n",
        "    user_info['name'] = input(\"What name would you like me to call you? \")\n",
        "    user_info['age'] = input(\"What is your age? \")\n",
        "    user_info['city'] = input(\"Which city are you from? \")\n",
        "    user_info['gender'] = input(\"What is your gender? \")\n",
        "    user_info['email'] = input(\"Please share your email address for support resources: \")\n",
        "\n",
        "    store_user_data(db, user_info)\n",
        "\n",
        "    print(f\"\\nThank you, {user_info['name']}. I'm Dr. James, and I'm here to support you.\")\n",
        "    print(\"This is a safe space where you can share anything that's on your mind.\")\n",
        "    print(\"Remember, you can type 'exit' whenever you'd like to end our session.\")\n",
        "\n",
        "    conversation_history = ConversationHistory()\n",
        "    qa_chain = setup_qa_chain(vector_db, llm)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nHuman: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Chatbot: Take care of yourself, Goodbye!\")\n",
        "            break\n",
        "\n",
        "        emotion, confidence = detect_emotion(query)\n",
        "        print(f\"Emotion Detected: {emotion} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "        if emotion == \"sadness\" and confidence > 0.75:\n",
        "            send_email(user_info['email'], user_info['city'])\n",
        "\n",
        "        conversation_history.add_message(\"Human\", query)\n",
        "        context = conversation_history.get_context()\n",
        "        response = qa_chain({\"query\": f\"{context}\\nUser: {query}\"})\n",
        "        chatbot_reply = response['result']\n",
        "        conversation_history.add_message(\"Chatbot\", chatbot_reply)\n",
        "\n",
        "        print(f\"Chatbot: {chatbot_reply}\")\n",
        "        store_chat_data(db, user_info, query, chatbot_reply, emotion, confidence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "6JMxcZk-aGjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J_Xr9vsujWTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}